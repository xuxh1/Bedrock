{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "from myfunc import timer\n",
    "from myfunc import DirMan\n",
    "from myfunc import load_and_flatten_data_nc\n",
    "from myfunc import load_and_flatten_data\n",
    "import config\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# configuration\n",
    "# resolution = \"0p1\"\n",
    "resolution = \"500\"\n",
    "region = [-180,180,-60,90]\n",
    "data_path = f'/tera04/zhwei/xionghui/bedrock/run/{resolution}/'\n",
    "post_data_path = '/tera04/zhwei/xionghui/bedrock/'\n",
    "shp_path = '/tera04/zhwei/xionghui/bedrock/Shp/'\n",
    "fig_path = f'/home/xuxh22/stu01/Bedrock/fig/{resolution}/'\n",
    "path = '/home/xuxh22/stu01/Bedrock/'\n",
    "if resolution == \"0p1\":\n",
    "    size = 0.1\n",
    "elif resolution == \"500\":\n",
    "    size = 0.0005\n",
    "\n",
    "dir_man = DirMan(data_path)\n",
    "dir_man.enter()\n",
    "\n",
    "os.makedirs(f'{data_path}/csv', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "with nc.Dataset('../../US/deficits/Sbedrock.nc') as dataset:\n",
    "    lat = dataset['lat'][:].flatten()\n",
    "    lon = dataset['lon'][:].flatten()\n",
    "    df['lat'] = np.repeat(lat, len(lon))\n",
    "    df['lon'] = np.tile(lon, len(lat))\n",
    "\n",
    "file_variable_list = [\n",
    "    ('../../US/deficits/Sbedrock', 'Band1'),\n",
    "    ('../../US/deficits/Sr', 'Band1'),\n",
    "    ('../../US/deficits/Sbedrock_dividedby_Sr', 'Band1'),\n",
    "    ('../../US/masks/masks_all_combined', 'Band1'),\n",
    "    ('../../US/products_used/gNATSGO/Ssoil_500m', 'Band1'),\n",
    "]\n",
    "\n",
    "for entry in file_variable_list:\n",
    "    file = entry[0]\n",
    "    variable_name = entry[1]  \n",
    "    index = entry[2:] if len(entry) > 2 else None  \n",
    "    if index:\n",
    "        df[file] = load_and_flatten_data_nc(file, variable_name, index[0])\n",
    "    else:\n",
    "        df[file] = load_and_flatten_data_nc(file, variable_name)\n",
    "\n",
    "df = df.dropna()\n",
    "df = df[df['../../US/deficits/Sbedrock'] > 0]\n",
    "df = df[df['../../US/masks/masks_all_combined'] > 0]\n",
    "\n",
    "shp = gpd.read_file(shp_path+'World_CN/ne_10m_admin_0_countries_chn.shp')\n",
    "df = df.reset_index(drop=True)\n",
    "gdf_points = gpd.GeoDataFrame(geometry=gpd.points_from_xy(df['lon'], df['lat']), crs='EPSG:4326')\n",
    "result = gpd.sjoin(gdf_points, shp, how='left', predicate='within')\n",
    "\n",
    "df['Sovereignt_short'] = result['ISO_A3']\n",
    "df1 = df[df['Sovereignt_short'] == 'USA']\n",
    "\n",
    "df1 = df1[(df1['lat']<=49.4) & (df1['lat']>=24.5)]\n",
    "df1 = df1[(df1['lon']<=-66.95) & (df1['lon']>=-124.8)]\n",
    "print(df1['../../US/deficits/Sbedrock'].mean())\n",
    "print(df1['../../US/deficits/Sr'].mean())\n",
    "print(df1['../../US/deficits/Sbedrock_dividedby_Sr'].mean())\n",
    "print(df1['../../US/products_used/gNATSGO/Ssoil_500m'].mean())\n",
    "\n",
    "with open('csv/US_nature.csv','w') as f:\n",
    "    df1.to_csv(f)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "with nc.Dataset('../../US/deficits/Sbedrock.nc') as dataset:\n",
    "    lat = dataset['lat'][:].flatten()\n",
    "    lon = dataset['lon'][:].flatten()\n",
    "    df['lat'] = np.repeat(lat, len(lon))\n",
    "    df['lon'] = np.tile(lon, len(lat))\n",
    "\n",
    "file_variable_list = [\n",
    "    ('../../US/products_used/gNATSGO/Ssoil_500m', 'Band1'),\n",
    "]\n",
    "\n",
    "for entry in file_variable_list:\n",
    "    file = entry[0]\n",
    "    variable_name = entry[1]  \n",
    "    index = entry[2:] if len(entry) > 2 else None  \n",
    "    if index:\n",
    "        df[file] = load_and_flatten_data_nc(file, variable_name, index[0])\n",
    "    else:\n",
    "        df[file] = load_and_flatten_data_nc(file, variable_name)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "shp = gpd.read_file(shp_path+'World_CN/ne_10m_admin_0_countries_chn.shp')\n",
    "df = df.reset_index(drop=True)\n",
    "gdf_points = gpd.GeoDataFrame(geometry=gpd.points_from_xy(df['lon'], df['lat']), crs='EPSG:4326')\n",
    "result = gpd.sjoin(gdf_points, shp, how='left', predicate='within')\n",
    "\n",
    "df['Sovereignt_short'] = result['ISO_A3']\n",
    "df1 = df[df['Sovereignt_short'] == 'USA']\n",
    "\n",
    "df1 = df1[(df1['lat']<=49.4) & (df1['lat']>=24.5)]\n",
    "df1 = df1[(df1['lon']<=-66.95) & (df1['lon']>=-124.8)]\n",
    "print(df1['../../US/products_used/gNATSGO/Ssoil_500m'].mean())\n",
    "\n",
    "with open('csv/US_nature_ssoil.csv','w') as f:\n",
    "    df1.to_csv(f)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "with nc.Dataset('../../US/deficits/Sbedrock_mask.nc') as dataset:\n",
    "    lat = dataset['lat'][:].flatten()\n",
    "    lon = dataset['lon'][:].flatten()\n",
    "    df['lat'] = np.repeat(lat, len(lon))\n",
    "    df['lon'] = np.tile(lon, len(lat))\n",
    "\n",
    "file_variable_list = [\n",
    "    ('../../US/deficits/Sbedrock_mask', 'Band1'),\n",
    "    ('../../US/deficits/Sr_mask', 'Band1'),\n",
    "    ('../../US/deficits/Sbedrock_dividedby_Sr_mask', 'Band1'),\n",
    "    ('../../mask/mask_US_nature/mask1234_US_nature', 'Band1'),\n",
    "    ('../../US/products_used/gNATSGO/Ssoil_500m_mask', 'Band1'),\n",
    "]\n",
    "\n",
    "for entry in file_variable_list:\n",
    "    file = entry[0]\n",
    "    variable_name = entry[1]  \n",
    "    index = entry[2:] if len(entry) > 2 else None  \n",
    "    if index:\n",
    "        df[file] = load_and_flatten_data(file, variable_name, index[0])\n",
    "    else:\n",
    "        df[file] = load_and_flatten_data(file, variable_name)\n",
    "\n",
    "df = df.dropna()\n",
    "df = df[df['../../US/deficits/Sbedrock_mask'] > 0]\n",
    "df = df[df['../../mask/mask_US_nature/mask1234_US_nature'] > 0]\n",
    "\n",
    "shp = gpd.read_file(shp_path+'World_CN/ne_10m_admin_0_countries_chn.shp')\n",
    "df = df.reset_index(drop=True)\n",
    "gdf_points = gpd.GeoDataFrame(geometry=gpd.points_from_xy(df['lon'], df['lat']), crs='EPSG:4326')\n",
    "result = gpd.sjoin(gdf_points, shp, how='left', predicate='within')\n",
    "\n",
    "df['Sovereignt_short'] = result['ISO_A3']\n",
    "df1 = df[df['Sovereignt_short'] == 'USA']\n",
    "\n",
    "df1 = df1[(df1['lat']<=49.4) & (df1['lat']>=24.5)]\n",
    "df1 = df1[(df1['lon']<=-66.95) & (df1['lon']>=-124.8)]\n",
    "print(df1['../../US/deficits/Sbedrock_mask'].mean())\n",
    "print(df1['../../US/deficits/Sr_mask'].mean())\n",
    "print(df1['../../US/deficits/Sbedrock_dividedby_Sr_mask'].mean())\n",
    "print(df1['../../US/products_used/gNATSGO/Ssoil_500m_mask'].mean())\n",
    "\n",
    "with open('csv/US_nature_mask.csv','w') as f:\n",
    "    df1.to_csv(f)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "with nc.Dataset('../../US/deficits/Sbedrock.nc') as dataset:\n",
    "    lat = dataset['lat'][:].flatten()\n",
    "    lon = dataset['lon'][:].flatten()\n",
    "    df['lat'] = np.repeat(lat, len(lon))\n",
    "    df['lon'] = np.tile(lon, len(lat))\n",
    "\n",
    "file_variable_list = [\n",
    "    ('../../US/products_used/gNATSGO/Ssoil_500m_mask', 'Band1'),\n",
    "]\n",
    "\n",
    "for entry in file_variable_list:\n",
    "    file = entry[0]\n",
    "    variable_name = entry[1]  \n",
    "    index = entry[2:] if len(entry) > 2 else None  \n",
    "    if index:\n",
    "        df[file] = load_and_flatten_data(file, variable_name, index[0])\n",
    "    else:\n",
    "        df[file] = load_and_flatten_data(file, variable_name)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "shp = gpd.read_file(shp_path+'World_CN/ne_10m_admin_0_countries_chn.shp')\n",
    "df = df.reset_index(drop=True)\n",
    "gdf_points = gpd.GeoDataFrame(geometry=gpd.points_from_xy(df['lon'], df['lat']), crs='EPSG:4326')\n",
    "result = gpd.sjoin(gdf_points, shp, how='left', predicate='within')\n",
    "\n",
    "df['Sovereignt_short'] = result['ISO_A3']\n",
    "df1 = df[df['Sovereignt_short'] == 'USA']\n",
    "\n",
    "df1 = df1[(df1['lat']<=49.4) & (df1['lat']>=24.5)]\n",
    "df1 = df1[(df1['lon']<=-66.95) & (df1['lon']>=-124.8)]\n",
    "print(df1['../../US/products_used/gNATSGO/Ssoil_500m_mask'].mean())\n",
    "\n",
    "with open('csv/US_nature_ssoil_mask.csv','w') as f:\n",
    "    df1.to_csv(f)\n",
    "\n",
    "df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
